#!/bin/bash

# LLK AI Issue Consultant - AI Response Preparation Script
#
# This script prepares the AI response template based on issue details
# and creates the response file for posting as a comment.

set -e

# Check required environment variables
if [ -z "$ISSUE_NUMBER" ] || [ -z "$ISSUE_TITLE" ] || [ -z "$ISSUE_AUTHOR" ] || [ -z "$ISSUE_LABELS" ]; then
  echo "âŒ Error: Missing required environment variables"
  echo "Required: ISSUE_NUMBER, ISSUE_TITLE, ISSUE_AUTHOR, ISSUE_LABELS"
  exit 1
fi

# Create a summary of the issue for logging
echo "ðŸ“‹ Issue Summary:"
echo "  Number: $ISSUE_NUMBER"
echo "  Title: $ISSUE_TITLE"
echo "  Author: $ISSUE_AUTHOR"
echo "  Labels: $ISSUE_LABELS"
echo "  URL: $ISSUE_URL"
echo ""
echo "ðŸ“ Issue Description:"
echo "$ISSUE_BODY"
echo ""
echo "ðŸ¤– Ready for AI analysis - prompt will be added in future update"

# Use generated prompt if available, otherwise fallback to default
if [ -n "$GENERATED_PROMPT" ] && [ "$PROMPT_SOURCE" = "generated" ]; then
  export AI_PROMPT="$GENERATED_PROMPT

Issue Description:
Title: $ISSUE_TITLE
Body: $ISSUE_BODY"
  echo "ðŸ§  Using AI-generated specialized prompt"
  echo "ðŸ“ Prompt source: $PROMPT_SOURCE"
elif [ -n "$GENERATED_PROMPT" ] && [ "$PROMPT_SOURCE" = "default" ]; then
  export AI_PROMPT="$GENERATED_PROMPT

Issue Description:
Title: $ISSUE_TITLE
Body: $ISSUE_BODY"
  echo "ðŸ”„ Using default prompt (AI generation failed)"
  echo "ðŸ“ Prompt source: $PROMPT_SOURCE"
else
  # Ultimate fallback if no prompt is available
  export AI_PROMPT="Given the following issue description do the following: 1. Determine and list which LLK APIs are relevant; 2. Within those APIs, list the Tensix instructions that are called; 3. Within those APIs, list the Tensix configuration registers that are programmed.

Issue Description:
Title: $ISSUE_TITLE
Body: $ISSUE_BODY"
  echo "âš™ï¸  Using hardcoded default prompt (no AI generation attempted)"
  echo "ðŸ“ Prompt source: hardcoded"
fi

# Export issue details for the TT-Chat script
export ISSUE_TITLE
export ISSUE_AUTHOR
export ISSUE_LABELS

echo ""
echo "ðŸ¤– AI Prompt prepared for TT-Chat:"
echo "$AI_PROMPT"
echo ""

# Check if we should use TT-Chat AI or fallback template
if [ "$USE_AI_API" = "true" ]; then
  echo "ðŸš€ Using TT-Chat API for LLK-focused AI analysis"
  # The TT-Chat API call will be handled by the workflow's github-script step
  echo "ai_use_real_api=true" >> $GITHUB_OUTPUT
else
  echo "ðŸ“ Using template response (set USE_AI_API=true to enable TT-Chat AI)"
  echo "ai_use_real_api=false" >> $GITHUB_OUTPUT

  # Create a structured response template that follows the requested analysis format

cat > ai_response.md << EOF
ðŸ¤– **LLK AI Consultant Analysis**

**Issue:** $ISSUE_TITLE
**Reporter:** @$ISSUE_AUTHOR
**Labels:** $ISSUE_LABELS

---

## Analysis Request
Given the issue description, I've analyzed the following aspects:

### 1. Relevant LLK APIs
*[AI Analysis Pending]*
- API analysis will be performed here
- Relevant Low Level Kernel APIs identified from the issue description
- Cross-references with LLK documentation and codebase

### 2. Tensix Instructions Called
*[AI Analysis Pending]*
- Specific Tensix instructions used by the identified APIs
- Instruction sequences and their purposes
- Performance implications and optimizations

### 3. Tensix Configuration Registers Programmed
*[AI Analysis Pending]*
- Configuration registers modified by the APIs
- Register settings and their effects
- Dependencies between register configurations

---

**Analysis Status:** â³ Awaiting AI integration
**Next Steps:**
- Complete AI prompt integration with TT-Chat
- Perform automated LLK API analysis using Tenstorrent's LLM
- Generate detailed Tensix instruction mapping

*This structured analysis template was generated by the LLK AI Issue Consultant workflow. The actual AI analysis will be performed by TT-Chat when enabled.*
EOF
fi

echo "âœ… AI response preparation completed"
echo "ai_response_ready=true" >> $GITHUB_OUTPUT
