operations:
  - src_a: "input_A"
    src_b: "input_B"
    output: "output1"
    src_b_const_value: 1.0
    src_a_dims: [32, 32]
    src_b_dims: [32, 32]
    output_dims: [32, 32]
    input_format: "Float16_b"
    output_format: "Float16_b"
    math:
      - type: "Fpu"
        operation: "Matmul"
        unpacker: "MatmulUnpacker"
    packer: "Packer"
    math_fidelity: "LoFi"
  - src_a: "input_A"
    src_b: "input_B"
    output: "output2"
    src_b_const_value: 1.0
    src_a_dims: [32, 32]
    src_b_dims: [32, 32]
    output_dims: [32, 32]
    input_format: "Float16_b"
    output_format: "Float16_b"
    math:
      - type: "Fpu"
        operation: "ReduceBlockMax"
        unpacker: "ReduceBlockMaxUnpacker"
    packer: "Packer"
    math_fidelity: "LoFi"
  - src_a: "input_A"
    src_b: "input_B"
    output: "output3"
    src_b_const_value: 1.0
    src_a_dims: [32, 32]
    src_b_dims: [32, 32]
    output_dims: [32, 32]
    input_format: "Float16_b"
    output_format: "Float16_b"
    math:
      - type: "Fpu"
        operation: "Elwadd"
        unpacker: "UnpackerAB"
        broadcast_type: "COL"
    packer: "Packer"
    math_fidelity: "LoFi"
  - src_a: "input_A"
    src_b: "input_B"
    output: "output4"
    src_b_const_value: 1.0
    src_a_dims: [32, 32]
    src_b_dims: [32, 32]
    output_dims: [32, 32]
    input_format: "Float16_b"
    output_format: "Float16_b"
    math:
      - type: "Fpu"
        operation: "Matmul"
        unpacker: "MatmulUnpacker"
    packer: "Packer"
    math_fidelity: "LoFi"
